{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_date = 20220326\n",
        "# outcome_list=['meloxicam', 'celecoxib', 'valproic_acid, lamotrigine']\n",
        "outcome_name = 'acetaminophen' \n",
        "outcome_name_list=[outcome_name]\n",
        "domains = ['measurement', 'drug', 'procedure', 'condition']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "current_dir = pathlib.Path.cwd()\n",
        "parent_dir = current_dir.parent\n",
        "preprocessing_output_dir = pathlib.Path('{}/data/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
        "output_dir = pathlib.Path('{}/result/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
        "pathlib.Path.mkdir(output_dir, mode=0o777, parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open('{}/0_importsql/abnormal_list.txt'.format(parent_dir), 'r') as f:\n",
        "#     data = f.read()\n",
        "# outcome_name_list = data.splitlines()\n",
        "# outcome_name_list=['abnormal_hepatotoxicity', 'abnormal_nephrotoxicity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_x_y_data(df, OBP) :\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    y_data = df['label'].T.reset_index(drop=True) #df['label'].T.drop_duplicates().T.reset_index(drop=True)\n",
        "    y_data = np.array(y_data)\n",
        "    y_data = y_data[0:len(y_data):OBP].reshape(-1, 1).astype(int)\n",
        "    #print(len(y_data), file=_logfile_)\n",
        "\n",
        "    x_df = df.drop('label', axis=1)\n",
        "\n",
        "    # 2-d data to 3-d data\n",
        "    timestamp = OBP \n",
        "    x_data = np.array(x_df)\n",
        "    x_data = x_data.reshape(-1, timestamp, x_data.shape[1]) # -1(sample), timestamp, column\n",
        "    #x_data.shape, y_data.shape\n",
        "\n",
        "    # get Column data\n",
        "    new_col = x_df.columns\n",
        "    print(x_data.shape, y_data.shape, len(new_col))\n",
        "    return x_data, y_data, new_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for linux\n",
        "import os\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from Auto_lstm_attention import *\n",
        "c = Auto_lstm_attention()\n",
        "error=[]\n",
        "\n",
        "for outcome_name in tqdm(outcome_name_list):\n",
        "    #try:\n",
        "        # 결과물 저장할 폴더 생성\n",
        "        output_domain_path = pathlib.Path('{}/{}'.format(output_dir, outcome_name))\n",
        "        pathlib.Path.mkdir(output_domain_path, mode=0o777, parents=True, exist_ok=True)\n",
        "                \n",
        "        concat_df = pd.read_csv('{}/{}.txt'.format(preprocessing_output_dir, outcome_name), index_col=False)\n",
        "        \n",
        "        # ##### Case 1 : Split by person_id #####\n",
        "        # id_data = concat_df[['person_id', 'label']].drop_duplicates().reset_index(drop=True)\n",
        "        # x_id_data = np.array(id_data['person_id'])\n",
        "        # y_id_data = np.array(id_data['label'])\n",
        "        \n",
        "        # x_id_train, x_id_test, y_id_train, y_id_test = train_test_split(x_id_data, y_id_data, test_size=0.3, random_state=1, stratify=y_id_data) \n",
        "        \n",
        "        # train_df = concat_df[concat_df['person_id'].isin(x_id_train)].reset_index(drop=True)\n",
        "        # test_df = concat_df[concat_df['person_id'].isin(x_id_test)].reset_index(drop=True)\n",
        "        \n",
        "        # train_df.to_csv('{}/{}_train.txt'.format(output_domain_path, outcome_name), index=False)\n",
        "        # test_df.to_csv('{}/{}_test.txt'.format(output_domain_path, outcome_name), index=False)\n",
        "        \n",
        "        # concat_df = concat_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
        "        # train_df = train_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
        "        # test_df = test_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
        "        \n",
        "        # x_data, y_data, new_col = split_x_y_data(concat_df, OBP=28)\n",
        "        # x_train, y_train, new_col = split_x_y_data(train_df, OBP=28)\n",
        "        # x_test, y_test, new_col = split_x_y_data(test_df, OBP=28)\n",
        "        \n",
        "        #### Case 2 : Split ignore person_id #####\n",
        "        concat_df = concat_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
        "    \n",
        "        x_data, y_data, new_col = split_x_y_data(concat_df, OBP=7)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1, stratify=y_data) \n",
        "        \n",
        "        c = Auto_lstm_attention()\n",
        "        model = c.LSTM_attention_building(x_train, x_test, y_train, y_test)\n",
        "        weights = c.class_balance_weight(output_domain_path, outcome_name, y_train)\n",
        "        h, y_hat = c.early_stopping_prediction()\n",
        "        c.classification_report(output_domain_path, outcome_name)\n",
        "        c.model_performance_evaluation(output_dir, outcome_name)\n",
        "        c.confusion_matrix_figure(output_domain_path, outcome_name)\n",
        "        c.confusion_matrix_figure2(output_domain_path, outcome_name)\n",
        "        AUC, ACC = c.ROC_AUC(output_domain_path, outcome_name)\n",
        "        c.loss(output_domain_path, outcome_name)\n",
        "        \n",
        "        if_ = c.attention_heatmap(new_col, output_domain_path, outcome_name)\n",
        "        accuracy = c.k_fold_cross_validation(x_data, y_data, output_domain_path, outcome_name)\n",
        "        \n",
        "        # # (['AUC','ACC','import_f', 'k_fold'])\n",
        "        # model.save('{}/{}.h5'.format(output_domain_path, outcome_name))\n",
        "\n",
        "        out = open('{}/output.txt'.format(output_dir),'a')\n",
        "        \n",
        "        out.write(str(outcome_name))\n",
        "        out.write('///' )\n",
        "        out.write(str(AUC ))\n",
        "        out.write('///' )\n",
        "        out.write(str(ACC ))\n",
        "        out.write('///' )\n",
        "        out.write(str(str(if_) ))\n",
        "        out.write('///' )\n",
        "        out.write(str(accuracy))\n",
        "        out.write('\\n')\n",
        "        \n",
        "        out.close()\n",
        "\n",
        "    #except:\n",
        "        print('except:', outcome_name)\n",
        "        error.append(outcome_name)\n",
        "    \n",
        "print(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "interpreter": {
      "hash": "e44f45f02e169a0d650cabd8d017218d9e9ad2905c0deaeb0a4156cdfc4ee6dc"
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
