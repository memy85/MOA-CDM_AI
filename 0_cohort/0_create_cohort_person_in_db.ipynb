{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# ** import package **\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.customlogger import customlogger as CL\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)    #각 컬럼 width 최대로 \n",
    "pd.set_option('display.max_rows', 50)        # display 50개 까지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# ** loading config **\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# ** loading info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]\n",
    "output_dir = pathlib.Path('{}/data/{}/create_cohort/'.format(parent_dir, current_date))\n",
    "pathlib.Path.mkdir(output_dir, mode=0o777, parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# **create Logger**\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")    \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# ** connection DataBase **\n",
    "if (cfg[\"dbms\"]==\"postgresql\"):\n",
    "    db_cfg = cfg[\"postgresql\"]\n",
    "    import psycopg2 as pg\n",
    "    conn = pg.connect(host=db_cfg['@server'], user=db_cfg['@user'], password=db_cfg['@password'], port=db_cfg['@port'], dbname=db_cfg['@database']) \n",
    "    conn.autocommit = True\n",
    "    log.debug(\"postgresql connect\")\n",
    "    \n",
    "elif (cfg[\"dbms\"]==\"mssql\"):\n",
    "    db_cfg = cfg[\"mssql\"]\n",
    "    import pymssql\n",
    "    conn= pymssql.connect(server=db_cfg['@server'], user=db_cfg['@user'], password=db_cfg['@password'], port=db_cfg['@port'], database=db_cfg['@database'], as_dict=False)\n",
    "    log.debug(\"mssql connect\")\n",
    "    \n",
    "else:\n",
    "    log.warning(\"set config.json - sql - dbms : mssql or postgresql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "def writefile(filepath, text):\n",
    "    abs_path = os.path.abspath(os.path.dirname(filepath))\n",
    "    pathlib.Path.mkdir(pathlib.Path(abs_path), mode=0o777, parents=True, exist_ok=True)\n",
    "    f = open(filepath, 'w')\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    \n",
    "def readfile(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    return text\n",
    "\n",
    "def executeQuery(conn, sql_query):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "        conn.commit()\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n",
    "\n",
    "def executeQuerynfetchone(conn, sql_query):\n",
    "    result = None\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "            result = cursor.fetchone()\n",
    "            if result != None:\n",
    "                result = result[0]\n",
    "        conn.commit()\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n",
    "    return result\n",
    "\n",
    "def renderTranslateQuerySql(sql_query, dict):\n",
    "    '''\n",
    "    ----- Replace text ------\n",
    "    \"@cdm_database_schema\",\n",
    "    \"@target_database_schema\",\n",
    "    \"@target_cohort_table\",\n",
    "    \"@vocabulary_database_schema\",\n",
    "    \"@target_cohort_id\"\n",
    "    ----- Replace text ------\n",
    "    '''\n",
    "    for key, value in dict.items():\n",
    "        sql_query = sql_query.replace(key, value)\n",
    "    return sql_query\n",
    "\n",
    "def checkemptyvalueindict(dict):\n",
    "    for key in dict:\n",
    "        if not dict[key]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# check drug concepts id \n",
    "sql_file_path = '../_sql/5_search_concept_ids/search_concept_ids_{dbms}.sql'\n",
    "sql_file_path = sql_file_path.replace(\"{dbms}\", cfg[\"dbms\"])\n",
    "\n",
    "dict_list = []\n",
    "output = pd.DataFrame()\n",
    "for drug in cfg['drug'].keys():\n",
    "    param_dict={}\n",
    "    param_dict['@cohort_database_schema'] = db_cfg['@cdm_database_schema']\n",
    "    param_dict['@drugname'] = drug\n",
    "    sql_query = readfile(sql_file_path)\n",
    "    sql_query = renderTranslateQuerySql(sql_query, param_dict)\n",
    "    # print(sql_query)\n",
    "    print(param_dict)\n",
    "    writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)\n",
    "    result = executeQuerynfetchone(conn, sql_query)\n",
    "    dict_list.append({'drug': drug, 'concept_id': result})\n",
    "    print(result)\n",
    "\n",
    "pd.DataFrame(dict_list).to_csv(\"{}/check_concept_id.txt\".format(output_dir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# create temp_cohort table \n",
    "for file_path in cfg['translatequerysql0']:\n",
    "    param_dict = cfg['translatequerysql0'][file_path]\n",
    "    sql_file_path = file_path.replace(\"{dbms}\", cfg[\"dbms\"])\n",
    "    print(sql_file_path)\n",
    "    print(param_dict)\n",
    "    sql_query = readfile(sql_file_path)\n",
    "    sql_query = renderTranslateQuerySql(sql_query, param_dict)\n",
    "    result = executeQuery(conn, sql_query)\n",
    "    writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]:\n",
    "# create total(case + control) person table\n",
    "for file_path in cfg['translatequerysql1']:\n",
    "    param_dict = cfg['translatequerysql1'][file_path]\n",
    "    for drug in cfg['drug'].keys():\n",
    "        sql_param_dict = param_dict.copy()\n",
    "        for param_key, param_value in sql_param_dict.items():\n",
    "            temp_param_value = param_value\n",
    "            temp_param_value = temp_param_value.replace(\"{drug}\", drug)\n",
    "            temp_param_value = temp_param_value.replace(\"{drug_target_cohort_id}\", cfg['drug'][drug][\"drug_target_cohort_id\"])\n",
    "            temp_param_value = temp_param_value.replace(\"{@drug_concept_set}\", cfg['drug'][drug][\"@drug_concept_set\"])\n",
    "            sql_param_dict[param_key] = temp_param_value\n",
    "\n",
    "        if checkemptyvalueindict(sql_param_dict):\n",
    "            continue\n",
    "        \n",
    "        sql_file_path = file_path.replace(\"{ade}\", cfg['drug'][drug][\"ade\"])\n",
    "        sql_file_path = sql_file_path.replace(\"{dbms}\", cfg[\"dbms\"])\n",
    "        sql_file_path = sql_file_path.replace(\"{drug}\", drug)\n",
    "        print(sql_file_path)\n",
    "        print(sql_param_dict)\n",
    "        sql_query = readfile(sql_file_path)\n",
    "        sql_query = renderTranslateQuerySql(sql_query, sql_param_dict)\n",
    "        result = executeQuery(conn, sql_query)\n",
    "        writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]:\n",
    "# create case person table\n",
    "for file_path in cfg['translatequerysql2']:\n",
    "    param_dict = cfg['translatequerysql2'][file_path]\n",
    "    for drug in cfg['drug'].keys():\n",
    "        sql_param_dict = param_dict.copy()\n",
    "        for param_key, param_value in sql_param_dict.items():\n",
    "            temp_param_value = param_value\n",
    "            temp_param_value = temp_param_value.replace(\"{drug}\", drug)\n",
    "            temp_param_value = temp_param_value.replace(\"{drug_target_cohort_id}\", cfg['drug'][drug][\"drug_target_cohort_id\"])\n",
    "            temp_param_value = temp_param_value.replace(\"{@drug_concept_set}\", cfg['drug'][drug][\"@drug_concept_set\"])\n",
    "            sql_param_dict[param_key] = temp_param_value\n",
    "\n",
    "        if checkemptyvalueindict(sql_param_dict):\n",
    "            continue\n",
    "        \n",
    "        sql_file_path = file_path.replace(\"{ade}\", cfg['drug'][drug][\"ade\"])\n",
    "        sql_file_path = sql_file_path.replace(\"{dbms}\", cfg[\"dbms\"])\n",
    "        sql_file_path = sql_file_path.replace(\"{drug}\", drug)\n",
    "        print(sql_file_path)\n",
    "        print(sql_param_dict)\n",
    "        sql_query = readfile(sql_file_path)\n",
    "        sql_query = renderTranslateQuerySql(sql_query, sql_param_dict)\n",
    "        result = executeQuery(conn, sql_query)\n",
    "        writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "# Check the number of created patients\n",
    "dict_list = []\n",
    "for drug in cfg['drug'].keys():\n",
    "    sql_query = \"select count(distinct person_id) from {}.person_{}_total\".format(db_cfg['@person_database_schema'], drug)\n",
    "    # print(\"select * from person_{}\".format(drug))\n",
    "    n_total_population = executeQuerynfetchone(conn, sql_query)\n",
    "    \n",
    "    sql_query = \"select count(distinct person_id) from {}.person_{}_case\".format(db_cfg['@person_database_schema'], drug)\n",
    "    # print(\"select * from person_{}\".format(drug))\n",
    "    n_case_population = executeQuerynfetchone(conn, sql_query)\n",
    "    \n",
    "    dict_list.append({'drug': drug, 'n_total_population': n_total_population, 'n_case_population': n_case_population})\n",
    "    \n",
    "pd.DataFrame(dict_list).to_csv(\"{}/check_numberofpatient.txt\".format(output_dir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]:\n",
    "# make person table from 2 cohort (1:3 sampling) \n",
    "for file_path in cfg['translatequerysql3']:\n",
    "    param_dict = cfg['translatequerysql3'][file_path]\n",
    "    for drug in cfg['drug'].keys():\n",
    "        sql_param_dict = param_dict.copy()\n",
    "        for param_key, param_value in sql_param_dict.items():\n",
    "            sql_param_dict[param_key] = param_value.replace(\"{drug}\", drug)\n",
    "        sql_file_path = file_path.replace(\"{dbms}\", cfg[\"dbms\"]).replace(\"{drug}\", drug)\n",
    "        print(sql_file_path)\n",
    "        print(sql_param_dict)\n",
    "        sql_query = readfile(sql_file_path)\n",
    "        sql_query = renderTranslateQuerySql(sql_query, sql_param_dict)\n",
    "        result = executeQuery(conn, sql_query)\n",
    "        writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[]:\n",
    "# create person_meas table for check the distribution of the patient's meas values (Not required.)\n",
    "for file_path in cfg['translatequerysql4']:\n",
    "    param_dict = cfg['translatequerysql4'][file_path]\n",
    "    for meas in cfg['meas'].keys():\n",
    "        sql_param_dict = param_dict.copy()\n",
    "        for param_key, param_value in sql_param_dict.items():\n",
    "            temp_param_value = param_value\n",
    "            temp_param_value = temp_param_value.replace(\"{meas}\", meas)\n",
    "            temp_param_value = temp_param_value.replace(\"{@meas_concept_id}\", cfg['meas'][meas][\"@meas_concept_id\"])\n",
    "            sql_param_dict[param_key] = temp_param_value\n",
    "        sql_file_path = file_path.replace(\"{dbms}\", cfg[\"dbms\"])\n",
    "        print(sql_file_path)\n",
    "        print(sql_param_dict)\n",
    "        sql_query = readfile(sql_file_path)\n",
    "        sql_query = renderTranslateQuerySql(sql_query, sql_param_dict)\n",
    "        result = executeQuery(conn, sql_query)\n",
    "        writefile(filepath=sql_file_path.replace('../_sql/','../query/{}/'.format(drug)), text=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e6cc6be75692257a476a3204c3a0d08d1f09081e1c059f9bf7314479d5625fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
