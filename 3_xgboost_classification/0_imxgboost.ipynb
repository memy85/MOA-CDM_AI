{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced XGBoost\n",
    "--------------\n",
    "변경사항\n",
    "- 1) current_date\n",
    "- 2) outcome_name ; 변경하면서 다시 재실행 \n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = 20220317\n",
    "# outcome_list=['meloxicam', 'celecoxib', 'valproic_acid, lamotrigine']\n",
    "outcome_name = 'meloxicam' \n",
    "domains = ['measurement', 'drug', 'procedure', 'condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meloxicam']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "data_dir = pathlib.Path('{}/data/{}/preprocess/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "output_result_dir = pathlib.Path('{}/result/{}/xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "file_list = os.listdir(data_dir)\n",
    "file_list = [pathlib.Path(filename).with_suffix('').name for filename in file_list]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_1 :  101\n",
      "label_0 :  6740\n",
      "data  :  (6841, 47) (6841,)\n",
      "train :  (4788, 47) (4788,)\n",
      "test  :  (2053, 47) (2053,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, cross_validate, GridSearchCV\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from model_estimation import *\n",
    "import functools\n",
    "\n",
    "concat_df = pd.read_csv('{}/{}.txt'.format(data_dir, outcome_name), index_col=False)\n",
    "\n",
    "concat_df['cohort_start_date'] = pd.to_datetime(concat_df['cohort_start_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "concat_df['first_abnormal_date'] = pd.to_datetime(concat_df['first_abnormal_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "concat_df['concept_date'] = pd.to_datetime(concat_df['concept_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "    \n",
    "# concat_df['duration'] = (concat_df['concept_date']-concat_df['cohort_start_date']).dt.days+1\n",
    "concat_df = concat_df.drop(['person_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "\n",
    "### @change column name ; column에 json파일 구분자가 들어가면 plot을 그리지 못함. \n",
    "import re\n",
    "concat_df.columns = concat_df.columns.str.translate(\"\".maketrans({\"[\":\"(\", \"]\":\")\"}))\n",
    "concat_df = concat_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_ /()]+', '', x))\n",
    "concat_df.columns\n",
    "\n",
    "### @환자수 확인\n",
    "print(\"label_1 : \",len(concat_df[concat_df[\"label\"] == 1]))\n",
    "print(\"label_0 : \",len(concat_df[concat_df[\"label\"] == 0]))\n",
    "\n",
    "### @x, y데이터 분할 \n",
    "def split_x_y_data(df) :\n",
    "    y_data = df['label'].T.reset_index(drop=True) \n",
    "    x_data = df.drop('label', axis=1)\n",
    "    new_col = x_data.columns\n",
    "    return x_data, y_data, new_col\n",
    "\n",
    "x_data, y_data, new_col = split_x_y_data(concat_df)\n",
    "\n",
    "### @train/test dataset 구분 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1, stratify=y_data)\n",
    "\n",
    "print(\"data  : \", x_data.shape, y_data.shape)\n",
    "print(\"train : \", x_train.shape, y_train.shape)\n",
    "print(\"test  : \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.603608\n",
      "RMSE: 0.187273\n",
      "RMSE: 0.103518\n",
      "RMSE(preds): 1.603608\n"
     ]
    }
   ],
   "source": [
    "### @ imblanced xgboost\n",
    "\n",
    "xgboster_focal = imb_xgb(special_objective='focal')\n",
    "xgboster_weight = imb_xgb(special_objective='weighted')\n",
    "CV_focal_booster = GridSearchCV(xgboster_focal, {\"focal_gamma\":[1.0,1.5,2.0,2.5,3.0]})\n",
    "CV_weight_booster = GridSearchCV(xgboster_weight, {\"imbalance_alpha\":[1.5,2.0,2.5,3.0,4.0]})\n",
    "\n",
    "CV_focal_booster.fit(x_train.to_numpy(), y_train.to_numpy())\n",
    "CV_weight_booster.fit(x_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "opt_focal_booster = CV_focal_booster.best_estimator_\n",
    "opt_weight_booster = CV_weight_booster.best_estimator_\n",
    "\n",
    "raw_output = opt_focal_booster.predict(x_test.to_numpy(), y=None)\n",
    "rmse = np.sqrt(mean_squared_error(y_test.to_numpy(), raw_output))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "sigmoid_output = opt_focal_booster.predict_sigmoid(x_test.to_numpy(), y=None) \n",
    "rmse = np.sqrt(mean_squared_error(y_test.to_numpy(), sigmoid_output))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "class_output = opt_focal_booster.predict_determine(x_test.to_numpy(), y=None) \n",
    "rmse = np.sqrt(mean_squared_error(y_test.to_numpy(), class_output))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "prob_output = opt_focal_booster.predict_two_class(x_test.to_numpy(), y=None) \n",
    "# rmse = np.sqrt(mean_squared_error(y_test.to_numpy(), prob_output))\n",
    "# print(\"RMSE(prob_output): %f\" % (rmse))\n",
    "\n",
    "preds = opt_focal_booster.predict(x_test.to_numpy(), y=None) \n",
    "rmse = np.sqrt(mean_squared_error(y_test.to_numpy(), preds))\n",
    "print(\"RMSE(preds): %f\" % (rmse))\n",
    "\n",
    "# retrieve the best parameters\n",
    "xgboost_opt_param = CV_focal_booster.best_params_\n",
    "# instantialize an imbalance-xgboost instance\n",
    "xgboost_opt = imb_xgb(special_objective='focal', **xgboost_opt_param)\n",
    "# cross-validation\n",
    "# initialize the splitter\n",
    "loo_splitter = LeaveOneOut()\n",
    "# initialize the score evalutation function by feeding the 'mode' argument\n",
    "# 'mode' can be [\\'accuracy\\', \\'precision\\',\\'recall\\',\\'f1\\',\\'MCC\\']\n",
    "score_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='accuracy')\n",
    "# Leave-One cross validation\n",
    "loo_info_dict = cross_validate(xgboost_opt, X=x_data.to_numpy(), y=y_data.to_numpy(), cv=loo_splitter, scoring=make_scorer(score_eval_func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Utility\\Python37\\lib\\site-packages\\xgboost\\data.py:728: UserWarning: Unknown data type: <class 'xgboost.core.DMatrix'>, trying to convert it to csr_matrix\n",
      "  UserWarning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Not supported type for data.<class 'xgboost.core.DMatrix'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9180\\1612639833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\home\\suncheol\\code\\CDM_LSTM_220221\\3_xgboost_classification\\imxgboost\\imbalance_xgb.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data_x, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test data invalid!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mprediction_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboosting_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Utility\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Utility\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[0mfeature_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m             \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m         )\n\u001b[0;32m    624\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Utility\\Python37\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Not supported type for data.'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Not supported type for data.<class 'xgboost.core.DMatrix'>"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(data=x_test , label=y_test)\n",
    "pred_probs = xgboost_opt.predict(dtest)\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "y_pred = [ 1 if x >= 0.5 else 0 for x in pred_probs ]\n",
    "get_clf_eval(y_test, y_pred, pred_probs)\n",
    "\n",
    "### @ save : plot tree & plot importance feature \n",
    "make_plot_tree(xgboost_opt.boosting_model, output_result_dir, outcome_name, rankdir=None)\n",
    "make_plot_tree(xgboost_opt.boosting_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "make_plot_importance(xgboost_opt.boosting_model, output_result_dir, outcome_name)\n",
    "\n",
    "### @ save : clf report & model estimation & confusion matrix & roc\n",
    "clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)\n",
    "\n",
    "### @ save : model json\n",
    "save_xgb_model_json(xgboost_opt.boosting_model, output_result_dir, outcome_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_opt_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_opt.correct_eval_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[]\n",
    "print(f\"scoring is invalid (got {scoring!r}). Refer to the \"\n",
    "        \"scoring glossary for details: \"\n",
    "        \"https://scikit-learn.org/stable/glossary.html#term-scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [TP_eval_func, TN_eval_func, FP_eval_func, FN_eval_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TP')\n",
    "TN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FP')\n",
    "FP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TN')\n",
    "FN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"scoring is invalid (got {make_scorer(TP_eval_func)!r}). Refer to the \"\n",
    "        \"scoring glossary for details: \"\n",
    "        \"https://scikit-learn.org/stable/glossary.html#term-scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the correctness evalutation function by feeding the 'mode' argument\n",
    "# 'mode' can be ['TP', 'TN', 'FP', 'FN']\n",
    "TP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TP')\n",
    "TN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FP')\n",
    "FP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TN')\n",
    "FN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FN')\n",
    "# define the score function dictionary\n",
    "score_dict = {'TP': make_scorer(TP_eval_func), \n",
    "              'FP': make_scorer(TN_eval_func), \n",
    "              'TN': make_scorer(FP_eval_func), \n",
    "              'FN': make_scorer(FN_eval_func)}\n",
    "\n",
    "score_dict.__name__ = \"evalutation function\"\n",
    "# Leave-One cross validation\n",
    "loo_info_dict = cross_validate(xgboost_opt, X=x_data.to_numpy(), y=y_data.to_numpy(), cv=loo_splitter, scoring=score_dict)\n",
    "overall_tp = np.sum(loo_info_dict['test_TP']).astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# class WrappablePartial(functools.partial):\n",
    "#     @property\n",
    "#     def __module__(self):\n",
    "#         return self.func.__module__\n",
    "#     @property\n",
    "#     def __name__(self):\n",
    "#         return \"functools.partial({}, *{}, **{})\".format(\n",
    "#             self.func.__name__,\n",
    "#             self.args,\n",
    "#             self.keywords\n",
    "#         )\n",
    "#     @property\n",
    "#     def __doc__(self):\n",
    "#         return self.func.__doc__\n",
    "   \n",
    "from functools import wraps\n",
    "\n",
    "TP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TP')\n",
    "TN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FP')\n",
    "FP_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='TN')\n",
    "FN_eval_func = functools.partial(xgboost_opt.score_eval_func, mode='FN')\n",
    "# define the score function dictionary\n",
    "score_dict = {'TP': make_scorer(TP_eval_func), \n",
    "              'FP': make_scorer(TN_eval_func), \n",
    "              'TN': make_scorer(FP_eval_func), \n",
    "              'FN': make_scorer(FN_eval_func)}\n",
    "# Leave-One cross validation\n",
    "loo_info_dict = cross_validate(xgboost_opt, X=x_data.to_numpy(), y=y_data.to_numpy(), cv=loo_splitter, scoring=score_dict)\n",
    "overall_tp = np.sum(loo_info_dict['test_TP']).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_opt.boosting_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train , label=y_train) \n",
    "dtest = xgb.DMatrix(data=x_test , label=y_test)\n",
    "\n",
    "params = { 'max_depth':5, 'learning_rate': 0.1, 'objective':'binary:logistic', 'eval_metric':'logloss' }\n",
    "num_rounds = 50\n",
    "# train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기합니다. \n",
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달 \n",
    "xgb_model = xgb.train(params = params, dtrain=dtrain, num_boost_round=num_rounds, early_stopping_rounds=200, evals=wlist )\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "y_pred = [ 1 if x >= 0.5 else 0 for x in pred_probs ]\n",
    "get_clf_eval(y_test, y_pred, pred_probs)\n",
    "\n",
    "make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir=None)\n",
    "make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "make_plot_importance(xgb_model, output_result_dir, outcome_name)\n",
    "\n",
    "clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)\n",
    "\n",
    "save_xgb_model_json(xgb_model, output_result_dir, outcome_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier, plot_importance\n",
    "\n",
    "# def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "#     model.fit(ftr_train, tgt_train)\n",
    "#     pred = model.predict(ftr_test)\n",
    "#     pred_proba = model.predict_proba(ftr_test)[:, 1]\n",
    "#     get_clf_eval(tgt_test, pred, pred_proba)\n",
    "        \n",
    "#     fig, ax = plt.subplots(figsize=(10,12))\n",
    "#     plot_importance(model, ax=ax)\n",
    "#     plt.show()\n",
    "    \n",
    "# lgbm_clf = LGBMClassifier(n_estimators=400, num_leaves=10, n_jobs=-1, boost_from_average=False)\n",
    "# get_model_train_eval(lgbm_clf, ftr_train=x_train, ftr_test=x_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "# xg_reg.fit(x_train,y_train)\n",
    "\n",
    "# pred_probs = xg_reg.predict(x_test)     \n",
    "\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, pred_probs))\n",
    "# print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "# # 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "# y_pred = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(data=x_data,label=y_data)\n",
    "\n",
    "# params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "#                 'max_depth': 5, 'alpha': 10}\n",
    "                \n",
    "# cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "#                     num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "                    \n",
    "# cv_results.head()\n",
    "# print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
    "\n",
    "# xgb_model = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=100)\n",
    "\n",
    "# make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir=None)\n",
    "# make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "# make_plot_importance(xgb_model, output_result_dir, outcome_name)\n",
    "\n",
    "# clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "# confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba9e2aafd4202ccdd325410855583e81bcee524d66662cf309288c7f44559fae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
