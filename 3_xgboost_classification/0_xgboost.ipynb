{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "--------------\n",
    "변경사항\n",
    "- 1) current_date\n",
    "- 2) outcome_name ; 변경하면서 다시 재실행 \n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcome_list=['meloxicam', 'celecoxib', 'valproic_acid, lamotrigine']\n",
    "outcome_name = 'acetaminophen' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "\n",
    "data_dir = pathlib.Path('{}/data/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "output_result_dir = pathlib.Path('{}/result/{}/xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "file_list = os.listdir(data_dir)\n",
    "file_list = [pathlib.Path(filename).with_suffix('').name for filename in file_list]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_estimation import *\n",
    "\n",
    "concat_df = pd.read_csv('{}/{}.txt'.format(data_dir, file_list[0]), index_col=False)\n",
    "\n",
    "concat_df['cohort_start_date'] = pd.to_datetime(concat_df['cohort_start_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "concat_df['first_abnormal_date'] = pd.to_datetime(concat_df['first_abnormal_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "concat_df['concept_date'] = pd.to_datetime(concat_df['concept_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "    \n",
    "# concat_df['duration'] = (concat_df['concept_date']-concat_df['cohort_start_date']).dt.days+1\n",
    "concat_df = concat_df.drop(['person_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "\n",
    "### @change column name ; column에 json파일 구분자가 들어가면 plot을 그리지 못함. \n",
    "import re\n",
    "concat_df.columns = concat_df.columns.str.translate(\"\".maketrans({\"[\":\"(\", \"]\":\")\"}))\n",
    "concat_df = concat_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_ /()]+', '', x))\n",
    "concat_df.columns\n",
    "\n",
    "### @환자수 확인\n",
    "print(\"label_1 : \",len(concat_df[concat_df[\"label\"] == 1]))\n",
    "print(\"label_0 : \",len(concat_df[concat_df[\"label\"] == 0]))\n",
    "\n",
    "### @x, y데이터 분할 \n",
    "def split_x_y_data(df) :\n",
    "    y_data = df['label'].T.reset_index(drop=True) \n",
    "    x_data = df.drop('label', axis=1)\n",
    "    new_col = x_data.columns\n",
    "    return x_data, y_data, new_col\n",
    "\n",
    "x_data, y_data, new_col = split_x_y_data(concat_df)\n",
    "\n",
    "### @train/test dataset 구분 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1, stratify=y_data)\n",
    "\n",
    "print(\"data  : \", x_data.shape, y_data.shape)\n",
    "print(\"train : \", x_train.shape, y_train.shape)\n",
    "print(\"test  : \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_weight = int(len(concat_df[concat_df[\"label\"] == 0])/len(concat_df[concat_df[\"label\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train , label=y_train) \n",
    "dtest = xgb.DMatrix(data=x_test , label=y_test)\n",
    "\n",
    "params = { 'max_depth':5, 'learning_rate': 0.1, 'objective':'binary:logistic', 'eval_metric':'logloss', 'scale_pos_weight': scale_weight}\n",
    "num_rounds = 200\n",
    "# train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기합니다. \n",
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달 \n",
    "class_weight= class_balance_weight(output_result_dir, outcome_name, y_train)\n",
    "    \n",
    "xgb_model = xgb.train(params = params, dtrain=dtrain, num_boost_round=num_rounds, early_stopping_rounds=200, evals=wlist)\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "y_pred = [ 1 if x >= 0.5 else 0 for x in pred_probs ]\n",
    "get_clf_eval(y_test, y_pred, pred_probs)\n",
    "\n",
    "### @ save : plot tree & plot importance feature \n",
    "make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir=None)\n",
    "make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "make_plot_importance(xgb_model, output_result_dir, outcome_name)\n",
    "\n",
    "### @ save : clf report & model estimation & confusion matrix & roc\n",
    "clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)\n",
    "\n",
    "### @ save : model json\n",
    "save_xgb_model_json(xgb_model, output_result_dir, outcome_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier, plot_importance\n",
    "\n",
    "# def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "#     model.fit(ftr_train, tgt_train)\n",
    "#     pred = model.predict(ftr_test)\n",
    "#     pred_proba = model.predict_proba(ftr_test)[:, 1]\n",
    "#     get_clf_eval(tgt_test, pred, pred_proba)\n",
    "        \n",
    "#     fig, ax = plt.subplots(figsize=(10,12))\n",
    "#     plot_importance(model, ax=ax)\n",
    "#     plt.show()\n",
    "    \n",
    "# lgbm_clf = LGBMClassifier(n_estimators=400, num_leaves=10, n_jobs=-1, boost_from_average=False)\n",
    "# get_model_train_eval(lgbm_clf, ftr_train=x_train, ftr_test=x_test, tgt_train=y_train, tgt_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "# xg_reg.fit(x_train,y_train)\n",
    "\n",
    "# pred_probs = xg_reg.predict(x_test)     \n",
    "\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, pred_probs))\n",
    "# print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "# # 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "# y_pred = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(data=x_data,label=y_data)\n",
    "\n",
    "# params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "#                 'max_depth': 5, 'alpha': 10}\n",
    "                \n",
    "# cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "#                     num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "                    \n",
    "# cv_results.head()\n",
    "# print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
    "\n",
    "# xgb_model = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=100)\n",
    "\n",
    "# make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir=None)\n",
    "# make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "# make_plot_importance(xgb_model, output_result_dir, outcome_name)\n",
    "\n",
    "# clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "# confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "# AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba9e2aafd4202ccdd325410855583e81bcee524d66662cf309288c7f44559fae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
