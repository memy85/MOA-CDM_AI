{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "### XGBoost\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** import package **\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from _utils.model_estimation import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading config **\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **create Logger**\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        ps_data_dir = pathlib.Path('{}/data/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        output_result_dir = pathlib.Path('{}/result/{}/xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "        concat_df = pd.read_csv('{}/{}.txt'.format(ps_data_dir, outcome_name), index_col=False)\n",
    "\n",
    "        concat_df['cohort_start_date'] = pd.to_datetime(concat_df['cohort_start_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "        concat_df['first_abnormal_date'] = pd.to_datetime(concat_df['first_abnormal_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "        concat_df['concept_date'] = pd.to_datetime(concat_df['concept_date'], format='%Y-%m-%d %H:%M:%S', errors='raise')\n",
    "            \n",
    "        # concat_df['duration'] = (concat_df['concept_date']-concat_df['cohort_start_date']).dt.days+1\n",
    "        concat_df = concat_df.drop(['person_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "\n",
    "        ### @change column name ; column에 json파일 구분자가 들어가면 plot을 그리지 못함. \n",
    "        import re\n",
    "        concat_df.columns = concat_df.columns.str.translate(\"\".maketrans({\"[\":\"(\", \"]\":\")\"}))\n",
    "        concat_df = concat_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_ /()]+', '', x))\n",
    "        concat_df.columns\n",
    "\n",
    "        ### @환자수 확인\n",
    "        print(\"label_1 : \",len(concat_df[concat_df[\"label\"] == 1]))\n",
    "        print(\"label_0 : \",len(concat_df[concat_df[\"label\"] == 0]))\n",
    "\n",
    "        ### @x, y데이터 분할 \n",
    "        def split_x_y_data(df) :\n",
    "            y_data = df['label'].T.reset_index(drop=True) \n",
    "            x_data = df.drop('label', axis=1)\n",
    "            new_col = x_data.columns\n",
    "            return x_data, y_data, new_col\n",
    "\n",
    "        x_data, y_data, new_col = split_x_y_data(concat_df)\n",
    "\n",
    "        ### @train/test dataset 구분 \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1, stratify=y_data)\n",
    "\n",
    "        print(\"data  : \", x_data.shape, y_data.shape)\n",
    "        print(\"train : \", x_train.shape, y_train.shape)\n",
    "        print(\"test  : \", x_test.shape, y_test.shape)\n",
    "        \n",
    "        scale_weight = int(len(concat_df[concat_df[\"label\"] == 0])/len(concat_df[concat_df[\"label\"] == 1]))\n",
    "\n",
    "        dtrain = xgb.DMatrix(data=x_train , label=y_train) \n",
    "        dtest = xgb.DMatrix(data=x_test , label=y_test)\n",
    "\n",
    "        params = { 'max_depth':5, 'learning_rate': 0.010, 'objective':'binary:logistic', 'eval_metric':'logloss', 'scale_pos_weight': scale_weight}\n",
    "        num_rounds = 1000\n",
    "        # train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기합니다. \n",
    "        wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "        # 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달 \n",
    "        class_weight= class_balance_weight(output_result_dir, outcome_name, y_train)\n",
    "            \n",
    "        xgb_model = xgb.train(params = params, dtrain=dtrain, num_boost_round=num_rounds, early_stopping_rounds=100, evals=wlist)\n",
    "        pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "        # 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds 에 저장\n",
    "        y_pred = [ 1 if x >= 0.5 else 0 for x in pred_probs ]\n",
    "        get_clf_eval(y_test, y_pred, pred_probs)\n",
    "\n",
    "        ### @ save : plot tree & plot importance feature \n",
    "        make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir=None)\n",
    "        make_plot_tree(xgb_model, output_result_dir, outcome_name, rankdir='LR')\n",
    "        make_plot_importance(xgb_model, output_result_dir, outcome_name)\n",
    "\n",
    "        ### @ save : clf report & model estimation & confusion matrix & roc\n",
    "        clf_report(y_test, y_pred, output_result_dir, outcome_name)\n",
    "        model_performance_evaluation(y_test, y_pred, pred_probs, output_result_dir, outcome_name)\n",
    "        confusion_matrix_figure(y_test, y_pred, output_result_dir, outcome_name)\n",
    "        confusion_matrix_figure2(y_test, y_pred, output_result_dir, outcome_name)\n",
    "        AUC, ACC = ROC_AUC(y_test, y_pred, output_result_dir, outcome_name)\n",
    "\n",
    "        ### @ save : model json\n",
    "        save_xgb_model_json(xgb_model, output_result_dir, outcome_name)\n",
    "    \n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
