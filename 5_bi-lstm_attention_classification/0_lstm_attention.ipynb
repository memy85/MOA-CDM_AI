{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "lstm attention \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** import package **\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from _utils.Auto_lstm_attention import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading config **\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **create Logger**\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linux\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        # In[ ]:\n",
    "        log.debug(\"{}\".format(outcome_name))\n",
    "        ps_data_dir = pathlib.Path('{}/data/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        output_dir = pathlib.Path('{}/result/{}/lstm_attention/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        pathlib.Path.mkdir(output_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "        def split_x_y_data(df, OBP) :\n",
    "            import numpy as np\n",
    "            import pandas as pd\n",
    "\n",
    "            y_data = df['label'].T.reset_index(drop=True) #df['label'].T.drop_duplicates().T.reset_index(drop=True)\n",
    "            y_data = np.array(y_data)\n",
    "            y_data = y_data[0:len(y_data):OBP].reshape(-1, 1).astype(int)\n",
    "            #print(len(y_data), file=_logfile_)\n",
    "\n",
    "            x_df = df.drop('label', axis=1)\n",
    "\n",
    "            # 2-d data to 3-d data\n",
    "            timestamp = OBP \n",
    "            x_data = np.array(x_df)\n",
    "            x_data = x_data.reshape(-1, timestamp, x_data.shape[1]) # -1(sample), timestamp, column\n",
    "            #x_data.shape, y_data.shape\n",
    "\n",
    "            # get Column data\n",
    "            new_col = x_df.columns\n",
    "            print(x_data.shape, y_data.shape, len(new_col))\n",
    "            return x_data, y_data, new_col\n",
    "\n",
    "        c = Auto_lstm_attention()\n",
    "                \n",
    "        concat_df = pd.read_csv('{}/{}.txt'.format(ps_data_dir, outcome_name), index_col=False)\n",
    "        \n",
    "        # ##### Case 1 : Split by person_id #####\n",
    "        # id_data = concat_df[['person_id', 'label']].drop_duplicates().reset_index(drop=True)\n",
    "        # x_id_data = np.array(id_data['person_id'])\n",
    "        # y_id_data = np.array(id_data['label'])\n",
    "        \n",
    "        # x_id_train, x_id_test, y_id_train, y_id_test = train_test_split(x_id_data, y_id_data, test_size=0.3, random_state=1, stratify=y_id_data) \n",
    "        \n",
    "        # train_df = concat_df[concat_df['person_id'].isin(x_id_train)].reset_index(drop=True)\n",
    "        # test_df = concat_df[concat_df['person_id'].isin(x_id_test)].reset_index(drop=True)\n",
    "        \n",
    "        # train_df.to_csv('{}/{}_train.txt'.format(output_dir, outcome_name), index=False)\n",
    "        # test_df.to_csv('{}/{}_test.txt'.format(output_dir, outcome_name), index=False)\n",
    "        \n",
    "        # concat_df = concat_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "        # train_df = train_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "        # test_df = test_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "        \n",
    "        # x_data, y_data, new_col = split_x_y_data(concat_df, OBP=28)\n",
    "        # x_train, y_train, new_col = split_x_y_data(train_df, OBP=28)\n",
    "        # x_test, y_test, new_col = split_x_y_data(test_df, OBP=28)\n",
    "        \n",
    "        #### Case 2 : Split ignore person_id #####\n",
    "        concat_df = concat_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "    \n",
    "        x_data, y_data, new_col = split_x_y_data(concat_df, OBP=7)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1, stratify=y_data) \n",
    "        \n",
    "        c = Auto_lstm_attention()\n",
    "        model = c.LSTM_attention_building(x_train, x_test, y_train, y_test)\n",
    "        weights = c.class_balance_weight(output_dir, outcome_name, y_train)\n",
    "        h, y_hat = c.early_stopping_prediction()\n",
    "        c.classification_report(output_dir, outcome_name)\n",
    "        c.model_performance_evaluation(output_dir, outcome_name)\n",
    "        c.confusion_matrix_figure(output_dir, outcome_name)\n",
    "        c.confusion_matrix_figure2(output_dir, outcome_name)\n",
    "        AUC, ACC = c.ROC_AUC(output_dir, outcome_name)\n",
    "        c.loss(output_dir, outcome_name)\n",
    "        \n",
    "        if_ = c.attention_heatmap(new_col, output_dir, outcome_name)\n",
    "        accuracy = c.k_fold_cross_validation(x_data, y_data, output_dir, outcome_name)\n",
    "        c.plotRiskChangeOverTime(output_dir, outcome_name, nSamples=15)\n",
    "        \n",
    "        # # (['AUC','ACC','import_f', 'k_fold'])\n",
    "        # model.save('{}/{}.h5'.format(output_dir, outcome_name))\n",
    "\n",
    "        out = open('{}/output.txt'.format(output_dir),'a')\n",
    "        \n",
    "        out.write(str(outcome_name))\n",
    "        out.write('///' )\n",
    "        out.write(str(AUC ))\n",
    "        out.write('///' )\n",
    "        out.write(str(ACC ))\n",
    "        out.write('///' )\n",
    "        out.write(str(str(if_) ))\n",
    "        out.write('///' )\n",
    "        out.write(str(accuracy))\n",
    "        out.write('\\n')\n",
    "        \n",
    "        out.close()\n",
    "\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbce16cf9b2d89791389f77a3b049591f8be631eec5ba22753c4e9c396fdb255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
