{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "preprocessing (XGBoost)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** import package **\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.preprocessing_xgboost import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading config **\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** loading info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **create Logger**\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        # In[ ]:\n",
    "        log.debug(\"{}\".format(outcome_name))\n",
    "\n",
    "        # input file path\n",
    "        importsql_output_dir = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        # output file path\n",
    "        output_dir = pathlib.Path('{}/data/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        pathlib.Path.mkdir(output_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "        # output file path (features)\n",
    "        output_result_dir = pathlib.Path('{}/result/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "        pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "        # In[]:\n",
    "        # @load data\n",
    "        meas_df = pd.read_csv('{}/{}_meas_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "        drug_df = pd.read_csv('{}/{}_drug_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "        proc_df = pd.read_csv('{}/{}_proc_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "        cond_df = pd.read_csv('{}/{}_cond_df.txt'.format(importsql_output_dir, outcome_name), low_memory=False)\n",
    "\n",
    "        # @fill concept_value\n",
    "        drug_df['concept_value'] = 1 # temp code\n",
    "        proc_df['concept_value'] = 1\n",
    "        cond_df['concept_value'] = 1\n",
    "\n",
    "        # @use only necessary columns\n",
    "        common_cols = ['person_id', 'age', 'sex', 'cohort_start_date', 'first_abnormal_date', 'concept_date', 'concept_id', 'concept_name', 'concept_value', 'concept_domain', 'label']\n",
    "\n",
    "        meas_df = meas_df[common_cols]\n",
    "        drug_df = drug_df[common_cols]\n",
    "        proc_df = proc_df[common_cols]\n",
    "        cond_df = cond_df[common_cols]\n",
    "\n",
    "        log.info(\"[nData] m : {} d : {} p : {}  c : {} all : {}\".format(len(meas_df), len(drug_df), len(proc_df), len(cond_df), (len(meas_df) + len(drug_df) + len(proc_df) + len(cond_df))))\n",
    "\n",
    "        # @valid data processing for cohorts.\n",
    "        meas_df = cohortConditionSetting(meas_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "        drug_df = cohortConditionSetting(drug_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "        proc_df = cohortConditionSetting(proc_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "        cond_df = cohortConditionSetting(cond_df, pre_observation_period=60, post_observation_peroid=60)\n",
    "\n",
    "        def average_duration_of_adverse_events(df):\n",
    "            df = df[['person_id', 'cohort_start_date', 'first_abnormal_date']].drop_duplicates() #.subject_id.unique()\n",
    "            df['c_f'] = df['first_abnormal_date'] - df['cohort_start_date']\n",
    "            # print(df['c_f'].describe())\n",
    "            return df['c_f'].mean().days\n",
    "\n",
    "        ndays = average_duration_of_adverse_events(cond_df)\n",
    "        log.debug('average_duration_of_adverse_events : {}'.format(ndays))\n",
    "\n",
    "        # person_df = meas_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "        # print(person_df.label.value_counts())\n",
    "        # person_df = drug_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "        # print(person_df.label.value_counts())\n",
    "        # person_df = proc_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "        # print(person_df.label.value_counts())\n",
    "        # person_df = cond_df[[\"person_id\", \"label\"]].drop_duplicates()\n",
    "        # print(person_df.label.value_counts())\n",
    "\n",
    "        # @variable selection\n",
    "        meas_vars_df = variant_selection_paired_t_test(meas_df)\n",
    "        drug_vars_df = variant_selection_mcnemar(drug_df)\n",
    "        proc_vars_df = variant_selection_mcnemar(proc_df)\n",
    "        cond_vars_df = variant_selection_mcnemar(cond_df)\n",
    "\n",
    "        # @variable selection\n",
    "        meas_vars_df = meas_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "        drug_vars_df = drug_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "        cond_vars_df = cond_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "        proc_vars_df = proc_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        log.info(\"[nVar] m : {} d : {} p : {}  c: {}\".format(len(meas_vars_df), len(drug_vars_df), len(proc_vars_df), len(cond_vars_df)))\n",
    "\n",
    "        meas_vars_df['concept_domain'] = 'meas'\n",
    "        drug_vars_df['concept_domain'] = 'drug'\n",
    "        proc_vars_df['concept_domain'] = 'proc'\n",
    "        cond_vars_df['concept_domain'] = 'cond'\n",
    "\n",
    "        all_domain_vars_df = pd.concat([meas_vars_df, drug_vars_df, cond_vars_df, proc_vars_df], axis=0, ignore_index=True)\n",
    "        # @variable selection (save)\n",
    "        all_domain_vars_df.to_csv('{}/{}_feature.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "\n",
    "        # @Extract only selected concepts from data frame\n",
    "        def extractSelectedConceptID(domain_df, concept_id_list):\n",
    "            extract_domain_df = domain_df[domain_df['concept_id'].isin(concept_id_list)]\n",
    "            print(len(concept_id_list), len(domain_df), len(extract_domain_df))\n",
    "            return extract_domain_df\n",
    "\n",
    "        meas_df2 = extractSelectedConceptID(meas_df, meas_vars_df.concept_id.unique())\n",
    "        drug_df2 = extractSelectedConceptID(drug_df, drug_vars_df.concept_id.unique())\n",
    "        proc_df2 = extractSelectedConceptID(proc_df, proc_vars_df.concept_id.unique())\n",
    "        cond_df2 = extractSelectedConceptID(cond_df, cond_vars_df.concept_id.unique())\n",
    "\n",
    "        # meas_df2 = extractSelectedConceptID(meas_df2, meas_common_features.concept_id.unique())\n",
    "        # drug_df2 = extractSelectedConceptID(drug_df2, drug_common_features.concept_id.unique())\n",
    "        # proc_df2 = extractSelectedConceptID(proc_df2, proc_common_features.concept_id.unique())\n",
    "        # cond_df2 = extractSelectedConceptID(cond_df2, cond_common_features.concept_id.unique())\n",
    "\n",
    "        all_domain_df = pd.concat([meas_df2, drug_df2, proc_df2, cond_df2], axis=0, ignore_index=True)\n",
    "        # all_domain_df.drop(all_domain_df[all_domain_df['concept_domain']=='drug'].index, inplace=True)\n",
    "\n",
    "        ## @성향점수 매칭 (Propensity Score matching)\n",
    "        # label1_df = all_domain_df.drop_duplicates(['person_id'])[all_domain_df['label']==1][['person_id', 'age']]\n",
    "        # label0_df = all_domain_df.drop_duplicates(['person_id'])[all_domain_df['label']==0][['person_id', 'age']]\n",
    "\n",
    "        # matched_df = get_matching_pairs(label1_df['age'], label0_df['age'], scaler=False)\n",
    "        # person_id_list = set(label0_df.loc[matched_df.index].person_id) | set(label1_df.person_id)\n",
    "\n",
    "        # def extract_selected_person_ids(domain_df, subject_id_list):\n",
    "        #     extract_domain_df = domain_df[domain_df['person_id'].isin(subject_id_list)]\n",
    "        #     print(len(subject_id_list), len(domain_df), len(extract_domain_df))\n",
    "        #     return extract_domain_df\n",
    "\n",
    "        # all_domain_df = extract_selected_person_ids(all_domain_df, person_id_list).reset_index(drop=True)\n",
    "        ## @성향점수 매칭 end\n",
    "    \n",
    "        # In[]:\n",
    "        pivot_data = pivotting(all_domain_df)\n",
    "\n",
    "        drop_cols = []\n",
    "        for col in pivot_data.columns:\n",
    "            if (len(pivot_data[pivot_data[col].notnull()])/len(pivot_data[col]) < 0.3):\n",
    "                drop_cols.append(col)\n",
    "\n",
    "        pivot_data = pivot_data.drop(drop_cols, axis='columns')\n",
    "\n",
    "        pivot_data = pivot_data.query(\"concept_date <= cohort_start_date\")\n",
    "        pivot_data = pivot_data.sort_values(by=[\"person_id\", \"concept_date\"], axis=0, ascending=[True, False]).reset_index(drop=True)\n",
    "        pivot_data = pivot_data.drop_duplicates(subset=['person_id'], keep = 'first')\n",
    "        pivot_data = pivot_data.fillna(0)\n",
    "\n",
    "        # # temp \n",
    "        # pivot_data.to_csv('{}/{}_pivot_data.csv'.format(output_features_dir, outcome_name), header=True, index=True)\n",
    "\n",
    "        domain_ids={}\n",
    "        domain_ids['meas'] = np.setdiff1d(meas_df2.concept_id.unique(), drop_cols)\n",
    "        domain_ids['drug'] = np.setdiff1d(drug_df2.concept_id.unique(), drop_cols)\n",
    "        domain_ids['proc'] = np.setdiff1d(proc_df2.concept_id.unique(), drop_cols)\n",
    "        domain_ids['cond'] = np.setdiff1d(cond_df2.concept_id.unique(), drop_cols)\n",
    "        print(len(domain_ids['meas']), len(domain_ids['drug']), len(domain_ids['proc']), len(domain_ids['cond']))\n",
    "\n",
    "        # # -------- time series data ---------\n",
    "        # interpolate_df = day_sequencing_interpolate(pivot_data, domain_ids)\n",
    "\n",
    "        # label_1 = interpolate_df[interpolate_df['label']==1]\n",
    "        # label_0 = interpolate_df[interpolate_df['label']==0]\n",
    "\n",
    "        # rolled_label1_d = shift_rolling_window(label_1, OBP=7, nShift=7, uid_index=1)\n",
    "        # rolled_label0_d = label_0_fitting(label_0, OBP=7, nShift=14, uid_index=(rolled_label1_d.unique_id.max()+1))\n",
    "\n",
    "        # # label 0 + label 1\n",
    "        # concat_df = pd.concat([rolled_label1_d, rolled_label0_d], sort=False)\n",
    "        # concat_df = concat_df.sort_values(['unique_id', 'concept_date'])\n",
    "        # # -------- time series data ---------\n",
    "\n",
    "        # def timeSeriesToTimeData(timeseries_df):\n",
    "        #     ts_df = timeseries_df.sort_values(['subject_id', 'concept_date'], ascending=[True, True])\n",
    "        #     td_df = ts_df.groupby('subject_id', as_index=False).max()\n",
    "        #     return td_df\n",
    "\n",
    "        # TimeData = timeSeriesToTimeData(pivot_data)\n",
    "        # TimeData.describe()\n",
    "\n",
    "        # Normalization (Min/Max Scalar)\n",
    "        concat_df = normalization(pivot_data)\n",
    "        concat_df = concat_df.dropna(axis=1)\n",
    "\n",
    "        # columns name : concept_id > concept_name\n",
    "        concept_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_name))\n",
    "        concat_df = concat_df.rename(concept_dict, axis='columns')\n",
    "\n",
    "        # Save File\n",
    "        concat_df.to_csv('{}/{}.txt'.format(output_dir, outcome_name), index=False, float_format='%g')\n",
    "\n",
    "        output={}\n",
    "        output['meas_whole_var'] = len(meas_df.concept_id.unique())\n",
    "        output['drug_whole_var'] = len(drug_df.concept_id.unique())\n",
    "        output['proc_whole_var'] = len(proc_df.concept_id.unique())\n",
    "        output['cond_whole_var'] = len(cond_df.concept_id.unique())\n",
    "        output['meas_selected_var'] = len(domain_ids['meas'])\n",
    "        output['drug_selected_var'] = len(domain_ids['drug'])\n",
    "        output['proc_selected_var'] = len(domain_ids['proc'])\n",
    "        output['cond_selected_var'] = len(domain_ids['cond'])\n",
    "        output['nPatient_label1'] = len(concat_df[concat_df[\"label\"] == 1])\n",
    "        output['nPatient_label0'] = len(concat_df[concat_df[\"label\"] == 0])\n",
    "\n",
    "        # print\n",
    "        print(output['meas_whole_var'], output['meas_selected_var'])\n",
    "        print(output['drug_whole_var'], output['drug_selected_var'])\n",
    "        print(output['proc_whole_var'], output['proc_selected_var'])\n",
    "        print(output['cond_whole_var'], output['cond_selected_var'])\n",
    "\n",
    "        out = open('{}/output.txt'.format(output_result_dir),'a')\n",
    "\n",
    "        out.write(str(outcome_name) + '///' )\n",
    "        out.write(str(output['meas_whole_var']) + '///')\n",
    "        out.write(str(output['meas_selected_var']) + '///')\n",
    "        out.write(str(output['drug_whole_var']) + '///')\n",
    "        out.write(str(output['drug_selected_var']) + '///')\n",
    "        out.write(str(output['proc_whole_var']) + '///')\n",
    "        out.write(str(output['proc_selected_var']) + '///')\n",
    "        out.write(str(output['cond_whole_var']) + '///')\n",
    "        out.write(str(output['cond_selected_var']) + '///')\n",
    "        out.write(str(output['nPatient_label1']) + '///')\n",
    "        out.write(str(output['nPatient_label0']) + '\\n')\n",
    "        out.close()\n",
    "        \n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e6cc6be75692257a476a3204c3a0d08d1f09081e1c059f9bf7314479d5625fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
